
# PigLatin: Diving Deeper

Thigns that you can do to a relation:

* LOAD STORE DUMP
    - STORE ratings INTO 'outRatings' USING PigStorage(':');
    - You can also use different types of storage, like JSON, etc
* FILTER DISTINCT FOREACH / GENERATE MAPREDUCE STREAM SAMPLE
    - MAPREDUCE - Allows you to actually write the MAP and REDUCE
    - STREAM - Exposes the iostream 
* JOIN COGROUP GROUP CROSS CUBE
    - COGROUP creates a separate tuple for each key, different to JOIN which just creates a tuple with both joined keys
    - GROUP = Reduce
    - CROSS - Combinations to relations = Cartesian product (OUTER JOIN)
    - CUBE - even bigger = can do CROSS on more columns. not widely used
* ORDER RANK LIMIT
    - RANK - assigns rank number (doesn't order, but adds column with sorted id)
    - LIMIT - Limits the output (for testing, etc)
* UNION SPLIT

# Diagnostics

* DESCRIBE
    - Prints out schema of relation
* EXPLAIN
    - Insight on how pig will execute a given query
* ILLUSTRATE
    - Goes further - takes a sample of each relation and shows sample of data to show what is going on in each step

# UDF's - User Defined Functions

* REGISTER
    - I have a JAR file with UDFs, please bring it in
* DEFINE 
    - ASsigns names to the functions
* IMPORT
    - Import macros into other pig scripts

(REUSE CODE)

# Some other functions and loaders

* Some
    - AVG
    - CONCAT
    - COUNT
    - MAX
    - MIN
    - SIZE
    - SUM
* PigStorage - fieldbased data, assumes there is a delimiter
* TextLoader - Even more basic, one line of input/output data per row
* JsonLoader - loads json
* AvroStorage - Serialization / deserialization
* ParquetLoader - Column oriented data format
* OrcStorage - compressed format
* HBaseStorage - can integrate Pig with HBASE

To learn more there is not enough time, but there are O'Reilly books that provide an overview. Hadoop the definitive guide. 

 
